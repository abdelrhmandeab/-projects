import json
import os
import numpy as np
import pandas as pd
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def map_ember_features(ember_data):
    """Map EMBER features to the 25 features required by ml_analyzer.py."""
    try:
        features = []
        
        # 1-3: Header sizes
        optional_header = ember_data.get('header', {}).get('optional', {})
        features.append(optional_header.get('SizeOfCode', 0))  # size_of_code
        features.append(optional_header.get('SizeOfInitializedData', 0))  # size_of_initialized_data
        features.append(optional_header.get('SizeOfUninitializedData', 0))  # size_of_uninitialized_data

        # 4-7: Section information
        sections = ember_data.get('section', {}).get('sections', [])
        entropy = [s.get('entropy', 0) for s in sections]
        virtual_size = [s.get('vsize', 0) for s in sections]
        raw_size = [s.get('size', 0) for s in sections]
        
        avg_entropy = np.mean(entropy) if entropy else 0
        max_entropy = np.max(entropy) if entropy else 0
        avg_virtual_size = np.mean(virtual_size) if virtual_size else 0
        avg_raw_size = np.mean(raw_size) if raw_size else 0
        
        features.append(avg_entropy)  # avg_entropy
        features.append(max_entropy)  # max_entropy
        features.append(avg_virtual_size)  # avg_virtual_size
        features.append(avg_raw_size)  # avg_raw_size

        # 8-9: Imports
        imports = ember_data.get('imports', {})
        dll_count = len(imports)
        import_count = sum(len(funcs) for funcs in imports.values())
        suspicious_import = 0
        for dll, funcs in imports.items():
            dll_lower = dll.lower()
            if 'kernel32' in dll_lower or 'user32' in dll_lower:
                suspicious_import = 1
            for func in funcs:
                func_lower = func.lower()
                if func_lower in ['virtualalloc', 'createthread', 'writeprocessmemory']:
                    suspicious_import = 1
        features.append(dll_count)  # dll_count
        features.append(suspicious_import)  # suspicious_import

        # 10: Suspicious section names
        suspicious_section_name = 0
        for section in sections:
            name = section.get('name', '').lower()
            if any(x in name for x in ['pack', 'upx', 'vmp', 'themida']):
                suspicious_section_name = 1
        features.append(suspicious_section_name)  # suspicious_section_name

        # 11: Section count
        features.append(len(sections))  # section_count

        # 12-13: Imports and exports
        features.append(import_count)  # import_count
        exports = len(ember_data.get('exports', []))
        features.append(exports)  # export_count

        # 14: Import/export ratio
        import_export_ratio = import_count / (exports + 1)  # Avoid division by zero
        features.append(import_export_ratio)  # import_export_ratio

        # 15-18: Data directories
        data_dirs = ember_data.get('datadirectories', [])
        has_debug = 0
        has_relocations = 0
        has_resources = 0
        has_signature = 0
        for dir_entry in data_dirs:
            if dir_entry.get('name') == 'DEBUG' and dir_entry.get('size', 0) > 0:
                has_debug = 1
            if dir_entry.get('name') == 'BASERELOC' and dir_entry.get('size', 0) > 0:
                has_relocations = 1
            if dir_entry.get('name') == 'RESOURCE' and dir_entry.get('size', 0) > 0:
                has_resources = 1
            if dir_entry.get('name') == 'SECURITY' and dir_entry.get('size', 0) > 0:
                has_signature = 1
        features.append(has_debug)  # has_debug
        features.append(has_relocations)  # has_relocations
        features.append(has_resources)  # has_resources
        features.append(has_signature)  # has_signature

        # 19-20: Resource approximation (using strings as proxy)
        strings = ember_data.get('strings', {})
        resource_count = strings.get('numstrings', 0)
        resource_size = strings.get('avlength', 0) * resource_count
        features.append(resource_count)  # resource_count
        features.append(resource_size)  # resource_size

        # 21-22: Section characteristics
        executable_sections = sum(1 for s in sections if s.get('props', '') in ['E', 'C'])
        writable_sections = sum(1 for s in sections if 'W' in s.get('props', ''))
        features.append(executable_sections)  # executable_sections
        features.append(writable_sections)  # writable_sections

        # 23: Suspicious image base
        image_base = optional_header.get('ImageBase', 0)
        suspicious_image_base = 1 if image_base < 0x10000 else 0
        features.append(suspicious_image_base)  # suspicious_image_base

        # 24-25: Linker version
        features.append(optional_header.get('MajorLinkerVersion', 0))  # major_linker_version
        features.append(optional_header.get('MinorLinkerVersion', 0))  # minor_linker_version

        return features
    except Exception as e:
        logger.error(f"Error mapping features: {e}")
        return None

def process_ember_jsonl(jsonl_file):
    """Process a JSONL file and extract features and labels."""
    features_list = []
    labels = []
    with open(jsonl_file, 'r') as f:
        for line in f:
            try:
                data = json.loads(line.strip())
                label = data.get('label')
                # Skip unlabeled samples
                if label not in [0, 1]:
                    continue
                features = map_ember_features(data)
                if features and len(features) == 25:  # Ensure correct number of features
                    features_list.append(features)
                    labels.append(label)
            except Exception as e:
                logger.warning(f"Error processing JSONL line: {e}")
    return features_list, labels

def main():
    # Replace with path to your EMBER JSONL files
    ember_dir = "C:/ember2018"
    jsonl_files = [
        os.path.join(ember_dir, f)
        for f in os.listdir(ember_dir)
        if f.startswith('train_features') and f.endswith('.jsonl')
    ]

    if not jsonl_files:
        logger.error("No training JSONL files found. Please check the directory.")
        return

    all_features = []
    all_labels = []
    for jsonl_file in jsonl_files:
        logger.info(f"Processing {jsonl_file}...")
        features, labels = process_ember_jsonl(jsonl_file)
        all_features.extend(features)
        all_labels.extend(labels)

    # Convert to numpy arrays
    X = np.array(all_features)
    y = np.array(all_labels)

    # Save features and labels
    np.save('features.npy', X)
    np.save('labels.npy', y)
    logger.info(f"Saved {len(X)} samples with {X.shape[1]} features to features.npy and labels.npy")

if __name__ == "__main__":
    main()